{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Settings\n",
    "use_ngrok = False #@param {type:\"boolean\"}\n",
    "ngrok_auth_key = \"\" #@param {type:\"string\"}\n",
    "use_localtunnel = False #@param {type:\"boolean\"}\n",
    "use_cloudflared = True #@param {type:\"boolean\"}\n",
    "branch = 'main' #@param [\"main\", \"dev\"]\n",
    "use_flash_attention = True #@param {type:\"boolean\"}\n",
    "save_models_to_gdrive = False #@param {type:\"boolean\"}\n",
    "save_images_to_gdrive = False #@param {type:\"boolean\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Extensions\n",
    "disabled_extensions = []\n",
    "\n",
    "image_browser = True #@param {type:\"boolean\"}\n",
    "interrogator = True #@param {type:\"boolean\"}\n",
    "mesh_gen = True #@param {type:\"boolean\"}\n",
    "prompt_styles = True #@param {type:\"boolean\"}\n",
    "segmentation = True #@param {type:\"boolean\"}\n",
    "upscaler = True #@param {type:\"boolean\"}\n",
    "training = True #@param {type:\"boolean\"}\n",
    "\n",
    "if not image_browser: disabled_extensions.append('kd-image-browser')\n",
    "if not interrogator: disabled_extensions.append('kd-interrogator')\n",
    "if not mesh_gen: disabled_extensions.append('kd-mesh-gen')\n",
    "if not prompt_styles: disabled_extensions.append('kd-prompt-styles')\n",
    "if not segmentation: disabled_extensions.append('kd-segmentation')\n",
    "if not upscaler: disabled_extensions.append('kd-upscaler')\n",
    "if not training: disabled_extensions.append('kd-training')\n",
    "\n",
    "disabled_extensions = str.join(',', disabled_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_models_to_gdrive or save_images_to_gdrive:\n",
    "  from google.colab import drive\n",
    "\n",
    "  drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "\n",
    "[gpu] = !nvidia-smi --query-gpu=gpu_name --format=csv,noheader\n",
    "print (gpu)\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "!git clone -b {branch} https://github.com/seruva19/kubin.git\n",
    "%cd /content/kubin\n",
    "\n",
    "!pip install -r requirements.txt\n",
    "if use_flash_attention:\n",
    "  !pip install https://github.com/seruva19/flash-attn-wheels/raw/main/torch2.0.0%2Bcu118/flash_attn-1.0.1-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_ngrok: \n",
    "  !pip install pyngrok\n",
    "  from pyngrok import ngrok\n",
    "  ngrok.set_auth_token(ngrok_auth_key)\n",
    "\n",
    "  tunnels = ngrok.get_tunnels()\n",
    "  for tunnel in tunnels:\n",
    "    ngrok.disconnect(tunnel.public_url)\n",
    "\n",
    "  print(ngrok.connect(7860, \"http\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_localtunnel:\n",
    "    !npm install -g localtunnel\n",
    "    lturl = !curl ipv4.icanhazip.com\n",
    "    print(\"endpoint IP for localtunnel:\")\n",
    "    print(lturl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cloudflared:\n",
    "    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 $(lsof -t -i tcp:7860)\n",
    "\n",
    "!python src/kubin.py \\\n",
    "  --cache-dir={\"/content/gdrive/MyDrive/kubin/models\" if save_models_to_gdrive else \"/content/kubin/models\"} \\\n",
    "  --output-dir={\"/content/gdrive/MyDrive/kubin/output\" if save_images_to_gdrive else \"/content/kubin/output\"} \\\n",
    "  --disabled-extensions={disabled_extensions} \\\n",
    "  --share={\"none\" if use_ngrok or use_localtunnel or use_cloudflared else \"gradio\"} \\\n",
    "  {\"--use-flash-attention\" if use_flash_attention else \"\"} & \\\n",
    "  {\"npx localtunnel --port 7860\" if use_localtunnel else \":\"} & \\\n",
    "  {\"cloudflared tunnel --url http://localhost:7860\" if use_cloudflared else \":\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
